{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torch.autograd import Variable\n",
    "from scipy.signal import convolve2d, correlate2d\n",
    "from torch.nn.modules.module import Module \n",
    "from torch.nn.parameter import Parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 646.1837768554688\n",
      "0\n",
      "1\n",
      "2\n",
      "1 624.7628784179688\n",
      "2 563.4927978515625\n",
      "0\n",
      "1\n",
      "3 626.2626953125\n",
      "0\n",
      "4 631.3937377929688\n",
      "0\n",
      "1\n",
      "5 623.3583984375\n",
      "0\n",
      "1\n",
      "6 620.7235107421875\n",
      "0\n",
      "7 610.9720458984375\n",
      "0\n",
      "1\n",
      "8 613.8134765625\n",
      "0\n",
      "1\n",
      "2\n",
      "9 620.3606567382812\n",
      "0\n",
      "1\n",
      "10 606.0026245117188\n",
      "0\n",
      "1\n",
      "11 601.18603515625\n",
      "0\n",
      "1\n",
      "12 595.4243774414062\n",
      "0\n",
      "13 561.39794921875\n",
      "0\n",
      "1\n",
      "14 582.379150390625\n",
      "15 283.6065673828125\n",
      "16 264.99932861328125\n",
      "0\n",
      "1\n",
      "17 560.0285034179688\n",
      "0\n",
      "1\n",
      "18 550.5244750976562\n",
      "0\n",
      "1\n",
      "2\n",
      "19 600.944091796875\n",
      "0\n",
      "20 479.3553161621094\n",
      "0\n",
      "21 458.43206787109375\n",
      "0\n",
      "22 428.9304504394531\n",
      "0\n",
      "1\n",
      "2\n",
      "23 571.8104858398438\n",
      "0\n",
      "24 359.0577697753906\n",
      "25 132.24212646484375\n",
      "26 123.10090637207031\n",
      "0\n",
      "1\n",
      "2\n",
      "27 513.3256225585938\n",
      "28 97.43161010742188\n",
      "29 83.44444274902344\n",
      "30 67.561767578125\n",
      "31 51.845882415771484\n",
      "0\n",
      "32 194.72825622558594\n",
      "0\n",
      "1\n",
      "2\n",
      "33 432.345703125\n",
      "0\n",
      "34 160.26953125\n",
      "0\n",
      "1\n",
      "2\n",
      "35 387.0917053222656\n",
      "0\n",
      "1\n",
      "2\n",
      "36 358.75018310546875\n",
      "37 58.29304504394531\n",
      "0\n",
      "1\n",
      "2\n",
      "38 295.6631774902344\n",
      "0\n",
      "39 123.5028076171875\n",
      "0\n",
      "1\n",
      "40 183.4274139404297\n",
      "41 74.0772933959961\n",
      "0\n",
      "42 105.82907104492188\n",
      "0\n",
      "1\n",
      "43 153.6756134033203\n",
      "0\n",
      "1\n",
      "2\n",
      "44 169.6017608642578\n",
      "0\n",
      "1\n",
      "45 121.85972595214844\n",
      "0\n",
      "46 77.14643096923828\n",
      "0\n",
      "1\n",
      "2\n",
      "47 126.54000854492188\n",
      "0\n",
      "1\n",
      "2\n",
      "48 106.90841674804688\n",
      "0\n",
      "49 57.02521896362305\n"
     ]
    }
   ],
   "source": [
    "class DynamicNet(torch.nn.Module):\n",
    "  def __init__(self, D_in, H, D_out):\n",
    "    \"\"\"\n",
    "    In the constructor we construct three nn.Linear instances that we will use\n",
    "    in the forward pass.\n",
    "    \"\"\"\n",
    "    super(DynamicNet, self).__init__()\n",
    "    self.input_linear = torch.nn.Linear(D_in, H)\n",
    "    self.middle_linear = torch.nn.Linear(H, H)\n",
    "    self.output_linear = torch.nn.Linear(H, D_out)\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\"\n",
    "    For the forward pass of the model, we randomly choose either 0, 1, 2, or 3\n",
    "    and reuse the middle_linear Module that many times to compute hidden layer\n",
    "    representations.\n",
    "\n",
    "    Since each forward pass builds a dynamic computation graph, we can use normal\n",
    "    Python control-flow operators like loops or conditional statements when\n",
    "    defining the forward pass of the model.\n",
    "\n",
    "    Here we also see that it is perfectly safe to reuse the same Module many\n",
    "    times when defining a computational graph. This is a big improvement from Lua\n",
    "    Torch, where each Module could be used only once.\n",
    "    \"\"\"\n",
    "    h_relu = self.input_linear(x).clamp(min=0)\n",
    "    for _ in range(random.randint(0, 3)):\n",
    "      h_relu = self.middle_linear(h_relu).clamp(min=0)\n",
    "      print(_)\n",
    "    y_pred = self.output_linear(h_relu)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs, and wrap them in Variables\n",
    "x = Variable(torch.randn(N, D_in))\n",
    "y = Variable(torch.randn(N, D_out), requires_grad=False)\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = DynamicNet(D_in, H, D_out)\n",
    "\n",
    "# Construct our loss function and an Optimizer. Training this strange model with\n",
    "# vanilla stochastic gradient descent is tough, so we use momentum\n",
    "criterion = torch.nn.MSELoss(size_average=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "for t in range(50):\n",
    "  # Forward pass: Compute predicted y by passing x to the model\n",
    "  y_pred = model(x)\n",
    "\n",
    "  # Compute and print loss\n",
    "  loss = criterion(y_pred, y)\n",
    "  print(t, loss.data[0])\n",
    "\n",
    "  # Zero gradients, perform a backward pass, and update the weights.\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ScipyConv2dFunction(Function):\n",
    "\n",
    "    def forward(self, input, filter):\n",
    "        result = correlate2d(input.numpy(), filter.numpy(), mode='valid')\n",
    "        self.save_for_backward(input, filter)\n",
    "        return torch.FloatTensor(result)\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        input, filter = self.saved_tensors\n",
    "        grad_input = convolve2d(grad_output.numpy(), filter.t().numpy(), mode='full')\n",
    "        grad_filter = convolve2d(input.numpy(), grad_output.numpy(), mode='valid')\n",
    "        return torch.FloatTensor(grad_input), torch.FloatTensor(grad_filter)\n",
    "\n",
    "\n",
    "class ScipyConv2d(Module):\n",
    "\n",
    "    def __init__(self, kh, kw):\n",
    "        super(ScipyConv2d, self).__init__()\n",
    "        self.filter = Parameter(torch.randn(kh, kw))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return ScipyConv2dFunction()(input, self.filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "-0.1020  1.5605 -1.0686\n",
      "-0.2980  2.5237  1.7542\n",
      "-0.4122 -1.3402  0.7986\n",
      "[torch.FloatTensor of size 3x3]\n",
      "]\n",
      "Variable containing:\n",
      " -4.6548  -4.6930   6.2275   3.7410   0.9282   8.3057  -7.3934   0.9007\n",
      "  2.3386  -0.6485  -3.1071   6.0794   0.9995  -0.5390   3.7227  -6.3905\n",
      " -5.2148   2.6129   0.3813   3.4625   6.2553   0.2443   1.3901   3.9625\n",
      "  6.3458   3.4977   3.0102  -1.8656  -1.8380  -4.3040  -6.7021   2.1303\n",
      " -3.1746   4.6386   2.4804   3.4398   8.2589  -0.8090  -2.3347   0.3112\n",
      "-12.5187  -1.3936  -2.9841  -5.7624   4.4910   4.3556   2.6807  -3.4560\n",
      " -2.0804  -1.7245  -3.4513  -3.2356   0.5486   1.5356   5.3615   3.6591\n",
      "  0.6862   8.9628  -1.9815   0.8887  -0.2660  -4.4332  -3.6838  -1.5195\n",
      "[torch.FloatTensor of size 8x8]\n",
      "\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 7 \n",
      " -0.0151  -0.1755  -0.3303  -0.3054   0.1388  -0.4923  -0.0809  -0.0476\n",
      "  0.3176   2.6824   1.8807  -2.3290   4.9381  -0.4209  -0.1795  -1.0871\n",
      " -1.4960  -3.9210   2.2281  -5.6227  -0.4100   2.0443   1.2385   1.1935\n",
      "  0.9189  -2.0347  -1.5676   3.4440   0.2371  -1.6548   0.3344   5.7405\n",
      "  1.6084   4.7278  -1.4988  -2.2219   6.5629  -1.3669   3.2425   2.1438\n",
      " -4.6830  -3.1234  13.6079   1.6598  -1.3688   0.0095   0.0338   3.2736\n",
      "  2.5730  -5.1929  -2.0225   9.9454   2.5864  -3.0646   0.9915   0.4931\n",
      "  1.7657   0.7555  -5.1775   1.8733   7.8608  -4.6693  -4.0317  -1.4551\n",
      " -3.5344   2.2583   3.7454  -8.4219   2.0974   3.1178  -3.6058 -10.2126\n",
      "  1.6134  -4.4072   2.3947   1.0461  -2.4340   0.2101   2.1428  -3.8753\n",
      "\n",
      "Columns 8 to 9 \n",
      "  0.0604  -0.1738\n",
      "  1.3528  -0.2557\n",
      " -3.9285   1.0269\n",
      " -0.1703  -2.0357\n",
      "  3.9379  -0.8022\n",
      "  1.3996   0.4715\n",
      "  2.2930  -0.7825\n",
      "  7.3572  -1.8813\n",
      "  4.1775   0.9433\n",
      " -1.2913   0.1447\n",
      "[torch.FloatTensor of size 10x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "module = ScipyConv2d(3, 3)\n",
    "print(list(module.parameters()))\n",
    "input = Variable(torch.randn(10, 10), requires_grad=True)\n",
    "output = module(input)\n",
    "print(output)\n",
    "output.backward(torch.randn(8, 8))\n",
    "print(input.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
